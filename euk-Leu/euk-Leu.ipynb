{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Previously, we looked at fungal leucine tRNAs in GtRNAdb. Next, we're going to look at all eukaryotic leucine tRNAs in GtRNAdb. This will involve two extra steps. I'll need to build a phylogenetic tree, which will be used for autodetection of identity elements. This will replace the hardcoded yeast IDEs. \n",
    "\n",
    "We've learned that in fungi, the lower bound for _percentage of tRNAs missing an IDE_ is 20% in a single species, while every single species contained at least one tRNA with the proper IDEs. So for autodetection of IDEs, what can we set as a cutoff? What if all but one species has the IDEs? This could mean that the one species has a mutated synthetase. We need to set a boundary for the amount of evidence that will convince us that a conserved position is an identity element. I'd say that if 80% of species within a clade have the IDE in at least one tRNA, then it's convincing. \n",
    "\n",
    "## Workflow\n",
    "One potential workflow is as follows:\n",
    "1. Generate multi-tiered phylogenetic tree\n",
    "2. Align and filter tRNAs from each clade\n",
    "3. For each clade, find and score potential IDEs.\n",
    "    - This includes base pairs and single bases.\n",
    "    - Scoring will need to take into account a) number of species with at least one tRNA with the IDE, and b) percent of tRNAs with the IDE within each species. (a) is a scalar, while (b) is a vector. So we'll take the product of (a) and the mean of (b), for a score between 0 and 1. Let $s$ be the number of subclades in the clade, while $s_i$ is the subset of subclades containing at least one tRNA with an IDE $i$. $s$ can refer to species (e.g. _S. cerevisiae_ within fungi) or clades (e.g. fungi within eukaryotes). Let $t_s$ be the number of tRNAs within a subclade $s$, and $t_i$ be the number of tRNAs containing an IDE $i$. Then: \n",
    "$$\\text{Score} = \\frac{s_i}{s}\\frac{\\sum^s{t_{s,i}}}{s}$$\n",
    "    - As a heuristic, we will not score any positions with $s_i < 0.8$.\n",
    "4. Imagine a phylogenetic tree with root R branching into clades A, B, and C. If steps #2-#4 are performed for each of A, B, and C, we will now want to perform a R-wide analysis of the IDEs identified within subclades A, B, and C. Since this IDE analysis is entirely computational, some phylogenetic context is necessary. Then, we will want to perform a t-test for the scores of each IDE, between R and A (or B or C). The null hypothesis is that they are the same, e.g. conserved. \n",
    "    - Alternatively, we can assume that positions without evolutionary pressure have scores that follow a normal distribution, with a mean of $0.25 \\cdot 0.25 = 0.0625$. But tRNAs are subject to a variety of compounding pressures, and have different evolutionary timelines, so actually, this is a silly assumption.\n",
    "    - Either way, we will need to apply multiple testing corrections.\n",
    "    \n",
    "Unfortunately, this would fail in the case where the same position is mutated among different clades - for example, maybe fungi have A35 while mammals have G35. This requires a positional analysis. Instead of counting the number of tRNAs with an IDE, we can look at the R-wide information content. In theory, low information content means conservation. \n",
    "\n",
    "Given a method for finding positional IDE information, we should start with a list of positional IDEs, then try to resolve nucleotides. This also eliminates the need for subclade IDE autodetection, and instead we can just take the base or nucleotide at the proper position. So, we'll need to develop a cutoff for entropy. This would be used to determine the position of the base. Then we'd have to figure out a clade-wide nucleotide, which also needs a cutoff. I'm not too worried about this second cutoff, since we can just say something like 80%, and reanalyze subclades - the important thing is the entropy of the position. \n",
    "\n",
    "## Revised workflow\n",
    "1. Generate multi-tiered phylogenetic tree\n",
    "2. Align and filter tRNAs from each clade\n",
    "3. **Find positions under entropy cutoff**\n",
    "4. Resolve nucleotides corresponding to positions, if possible.\n",
    "5. Resolve nucleotides for subclades.\n",
    "\n",
    "In this notebook, I'll be performing this analysis for eukaryotic leucine tRNAs in order to find an appropriate entropy cutoff. Leucine is a good system since it is well studied, and has shared as well as differing IDEs between yeast and human. \n",
    "\n",
    "Later, we will want to look at identity element \"suites\" - what combinations of identity elements can be persistently found throughout a clade? This would be able to match the brain-specific arginine across species.\n",
    "\n",
    "### Yeast/human leucine IDEs\n",
    "Shared     |Yeast    |Human           |\n",
    ":--------|---------|-----------------:\n",
    "A73      |G35, G37 |C3:G70, A4:U69, G5:C68, C20a\n",
    "\n",
    "We have a couple of options for determining entropy.\n",
    "\n",
    "First, we can parse the alignment itself. For example, there are 925 As, 4 Us, and 21 Gs at position 73. There are also 2 Ns and 2 '-'s, which we don't count. Average entropy here is\n",
    "\n",
    "$$-\\sum^np_i\\log_2{p_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19225738255857028"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log2\n",
    "-925/950*log2(925/950) - 4/950*log2(4/950) - 21/950*log2(21/950)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at position 69, this is the entropy you'd see from a typical position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "935"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 184 As, 36 Gs, 426 Us, 289 Cs\n",
    "184+36+426+289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6827342976356228"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(n, total): return -n/total*log2(n/total)\n",
    "entropy(184, 935) + entropy(36, 935) + entropy(426, 935) + entropy(289, 935)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought about building a covariance model and parse the file to get emission log-odds bit scores for each possible nucleotide or base pair. This is different from what I calculated above: odds and probability are different. \n",
    "\n",
    "It's not clear how to consolidate log-odds into single positional scores. Range is loosely correlated with conservation for strong IDEs, but what if we had a subclade mutate the base at that position? Then for the position, we'd see a smaller range of bit scores, and it would be indistinguishable from variation. Overall, not being able to resolve multiple log odds scores into a scalar is probably because the range of possible odds is [0, $\\infty$]. Unlike probabilities, which sum to 1, odds are unbounded. What we could do is recover the probabilities by taking the root inverse log. Then we can aggregate them using the above process.\n",
    "\n",
    "But that would take too long, and we're trying to get a move on here. We'll stick with the former, finding positions with minimum entropy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding an entropy cutoff\n",
    "\n",
    "We'll come back to building a phylogenetic tree later. First, we'll get the entropy at each position and see if there's an easy cutoff. We use the R2 alignment used to build the leucine-specific CM, and also just the fungal tRNAs. Again, we use `--matchonly` to get the proper numbering, and ignore potential insertions/deletions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp ../gtrnadb-fungi/fungi-Leu-tRNAs.sto .\n",
    "cp ../../tRNAscan/models/1.6/fasta/euk-Leu-r2-031616.fa euk-Leu.fa\n",
    "cmalign -g --notrunc --matchonly -o euk-Leu.sto /projects/lowelab/users/blin/tRNAscan/models/current/TRNAinf-euk-Leu.cm euk-Leu.fa > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to dynamically determine what the secondary structure looks like. I use a combination of Sprinzl numbering and region numbering to track positions, since there are some weird tRNAs out there (variable loop, long D arm/D loop, G0, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7), (9, 13), (13, 22), (22, 26), (27, 32), (32, 39), (39, 44), (45, 49), (49, 53), (53, 57), (59, 64), (64, 71), (71, 76), (76, 83)]\n",
      "0 Region acceptor (0 ~ 7) 0\n",
      "0 Region acceptor (0 ~ 7) 1\n",
      "0 Region acceptor (0 ~ 7) 2\n",
      "0 Region acceptor (0 ~ 7) 3\n",
      "0 Region acceptor (0 ~ 7) 4\n",
      "0 Region acceptor (0 ~ 7) 5\n",
      "0 Region acceptor (0 ~ 7) 6\n",
      "1 Region dstem (9 ~ 13) 7\n",
      "1 Region dstem (9 ~ 13) 8\n",
      "1 Region dstem (9 ~ 13) 9\n",
      "1 Region dstem (9 ~ 13) 10\n",
      "1 Region dstem (9 ~ 13) 11\n",
      "1 Region dstem (9 ~ 13) 12\n",
      "2 Region dloop (13 ~ 22) 13\n",
      "2 Region dloop (13 ~ 22) 14\n",
      "2 Region dloop (13 ~ 22) 15\n",
      "2 Region dloop (13 ~ 22) 16\n",
      "2 Region dloop (13 ~ 22) 17\n",
      "2 Region dloop (13 ~ 22) 18\n",
      "2 Region dloop (13 ~ 22) 19\n",
      "2 Region dloop (13 ~ 22) 20\n",
      "2 Region dloop (13 ~ 22) 21\n",
      "3 Region dstem (22 ~ 26) 22\n",
      "3 Region dstem (22 ~ 26) 23\n",
      "3 Region dstem (22 ~ 26) 24\n",
      "3 Region dstem (22 ~ 26) 25\n",
      "4 Region acstem (27 ~ 32) 26\n",
      "4 Region acstem (27 ~ 32) 27\n",
      "4 Region acstem (27 ~ 32) 28\n",
      "4 Region acstem (27 ~ 32) 29\n",
      "4 Region acstem (27 ~ 32) 30\n",
      "4 Region acstem (27 ~ 32) 31\n",
      "5 Region acloop (32 ~ 39) 32\n",
      "5 Region acloop (32 ~ 39) 33\n",
      "5 Region acloop (32 ~ 39) 34\n",
      "5 Region acloop (32 ~ 39) 35\n",
      "5 Region acloop (32 ~ 39) 36\n",
      "5 Region acloop (32 ~ 39) 37\n",
      "5 Region acloop (32 ~ 39) 38\n",
      "6 Region acstem (39 ~ 44) 39\n",
      "6 Region acstem (39 ~ 44) 40\n",
      "6 Region acstem (39 ~ 44) 41\n",
      "6 Region acstem (39 ~ 44) 42\n",
      "6 Region acstem (39 ~ 44) 43\n",
      "7 Region vstem (45 ~ 49) 44\n",
      "7 Region vstem (45 ~ 49) 45\n",
      "7 Region vstem (45 ~ 49) 46\n",
      "7 Region vstem (45 ~ 49) 47\n",
      "7 Region vstem (45 ~ 49) 48\n",
      "8 Region vloop (49 ~ 53) 49\n",
      "8 Region vloop (49 ~ 53) 50\n",
      "8 Region vloop (49 ~ 53) 51\n",
      "8 Region vloop (49 ~ 53) 52\n",
      "9 Region vstem (53 ~ 57) 53\n",
      "9 Region vstem (53 ~ 57) 54\n",
      "9 Region vstem (53 ~ 57) 55\n",
      "9 Region vstem (53 ~ 57) 56\n",
      "10 Region tpcstem (59 ~ 64) 57\n",
      "10 Region tpcstem (59 ~ 64) 58\n",
      "10 Region tpcstem (59 ~ 64) 59\n",
      "10 Region tpcstem (59 ~ 64) 60\n",
      "10 Region tpcstem (59 ~ 64) 61\n",
      "10 Region tpcstem (59 ~ 64) 62\n",
      "10 Region tpcstem (59 ~ 64) 63\n",
      "11 Region tpcloop (64 ~ 71) 64\n",
      "11 Region tpcloop (64 ~ 71) 65\n",
      "11 Region tpcloop (64 ~ 71) 66\n",
      "11 Region tpcloop (64 ~ 71) 67\n",
      "11 Region tpcloop (64 ~ 71) 68\n",
      "11 Region tpcloop (64 ~ 71) 69\n",
      "11 Region tpcloop (64 ~ 71) 70\n",
      "12 Region tpcstem (71 ~ 76) 71\n",
      "12 Region tpcstem (71 ~ 76) 72\n",
      "12 Region tpcstem (71 ~ 76) 73\n",
      "12 Region tpcstem (71 ~ 76) 74\n",
      "12 Region tpcstem (71 ~ 76) 75\n",
      "13 Region acstem (76 ~ 83) 76\n",
      "13 Region acstem (76 ~ 83) 77\n",
      "13 Region acstem (76 ~ 83) 78\n",
      "13 Region acstem (76 ~ 83) 79\n",
      "13 Region acstem (76 ~ 83) 80\n",
      "13 Region acstem (76 ~ 83) 81\n",
      "13 Region acstem (76 ~ 83) 82\n",
      "Position 1:83 (acceptor #1)\n",
      "Position 2:82 (acceptor #2)\n",
      "Position 3:81 (acceptor #3)\n",
      "Position 4:80 (acceptor #4)\n",
      "Position 5:79 (acceptor #5)\n",
      "Position 6:78 (acceptor #6)\n",
      "Position 7:77 (acceptor #7)\n",
      "Position 8 (single #1)\n",
      "Position 9 (single #2)\n",
      "Position 10:26 (dstem #1)\n",
      "Position 11:25 (dstem #2)\n",
      "Position 12:24 (dstem #3)\n",
      "Position 13:23 (dstem #4)\n",
      "Position 14 (dloop #1)\n",
      "Position 15 (dloop #2)\n",
      "Position 16 (dloop #3)\n",
      "Position 17 (dloop #4)\n",
      "Position 18 (dloop #5)\n",
      "Position 19 (dloop #6)\n",
      "Position 20 (dloop #7)\n",
      "Position 21 (dloop #8)\n",
      "Position 22 (dloop #9)\n",
      "Position 27 (single #1)\n",
      "Position 28:44 (acstem #1)\n",
      "Position 29:43 (acstem #2)\n",
      "Position 30:42 (acstem #3)\n",
      "Position 31:41 (acstem #4)\n",
      "Position 32:40 (acstem #5)\n",
      "Position 33 (acloop #1)\n",
      "Position 34 (acloop #2)\n",
      "Position 35 (acloop #3)\n",
      "Position 36 (acloop #4)\n",
      "Position 37 (acloop #5)\n",
      "Position 38 (acloop #6)\n",
      "Position 39 (acloop #7)\n",
      "Position 45 (single #1)\n",
      "Position 46:57 (vstem #1)\n",
      "Position 47:56 (vstem #2)\n",
      "Position 48:55 (vstem #3)\n",
      "Position 49:54 (vstem #4)\n",
      "Position 50 (vloop #1)\n",
      "Position 51 (vloop #2)\n",
      "Position 52 (vloop #3)\n",
      "Position 53 (vloop #4)\n",
      "Position 58 (single #1)\n",
      "Position 59 (single #2)\n",
      "Position 60:76 (tpcstem #1)\n",
      "Position 61:75 (tpcstem #2)\n",
      "Position 62:74 (tpcstem #3)\n",
      "Position 63:73 (tpcstem #4)\n",
      "Position 64:72 (tpcstem #5)\n",
      "Position 65 (tpcloop #1)\n",
      "Position 66 (tpcloop #2)\n",
      "Position 67 (tpcloop #3)\n",
      "Position 68 (tpcloop #4)\n",
      "Position 69 (tpcloop #5)\n",
      "Position 70 (tpcloop #6)\n",
      "Position 71 (tpcloop #7)\n",
      "Position 84 (single #1)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "def calculate_positional_entropy(positions):\n",
    "    for position in positions: print(position)\n",
    "\n",
    "def parse_alignment(input_file):\n",
    "    alignment_fhandle = open(input_file)\n",
    "    positions = [] # list containing each position in the tRNA\n",
    "\n",
    "    # first, get secondary structure\n",
    "    for line in alignment_fhandle:\n",
    "        if line[0:12] == '#=GC SS_cons':\n",
    "            ss = line.strip().split()[-1]\n",
    "    \n",
    "    # parse secondary structure into regions and positions\n",
    "    positions = annotate_positions(ss)\n",
    "    \n",
    "    # get counts for each position by parsing Stockholm file\n",
    "    #positions = count_positions(input_file, positions)\n",
    "    \n",
    "    \n",
    "def annotate_positions(ss):\n",
    "    loop_indices = [r.span() for r in re.finditer('\\(+|<+|_+|>+|\\)+', ss)]\n",
    "    if len(loop_indices) == 14: regions = ['acceptor', 'dstem', 'dloop', 'dstem', 'acstem', 'acloop', 'acstem', 'vstem', 'vloop', 'vstem', 'tpcstem', 'tpcloop', 'tpcstem', 'acstem']\n",
    "    elif len(loop_indices) == 11: regions = ['acceptor', 'dstem', 'dloop', 'dstem', 'acstem', 'acloop', 'acstem', 'tpcstem', 'tpcloop', 'tpcstem', 'acstem']\n",
    "    regions = [Region(indices[0], indices[1], name) for indices, name in zip(loop_indices, regions[:])]\n",
    "    region = regions[0]\n",
    "    positions = []\n",
    "    region_index = 0 # index to be used to iterate through regions list\n",
    "    region_numbering = 0 # base numbering within a region\n",
    "    for position in range(len(ss)):\n",
    "        if region_index < len(regions):\n",
    "            region = regions[region_index]\n",
    "        else:\n",
    "            positions.append(Position(position=str(position + 1), region='single', region_number=region_numbering + 1, paired=False))\n",
    "            continue\n",
    "        print(region_index, regions[region_index], position)\n",
    "        if position < region.lower: # before the next region starts (or if it's the last region), annotate as single bases\n",
    "            positions.append(Position(position=str(position + 1), region='single', region_number=region_numbering + 1, paired=False))\n",
    "            region_numbering += 1\n",
    "        elif position == region.lower: # start of region: begin region numbering at 1\n",
    "            if ss[position] == \"(\":\n",
    "                paired_base = regions[-1].upper - 1\n",
    "                positions.append(Position(position='{}:{}'.format(position + 1, paired_base + 1), region=region.name, region_number=1, paired=True))\n",
    "            elif ss[position] == \"<\":\n",
    "                paired_base = regions[region_index + 2].upper - 1\n",
    "                positions.append(Position(position='{}:{}'.format(position + 1, paired_base + 1), region=region.name, region_number=1, paired=True))\n",
    "            elif ss[position] in [')', '>']:\n",
    "                pass\n",
    "            else:\n",
    "                positions.append(Position(position=str(position + 1), region=region.name, region_number=region_numbering + 1, paired=False))\n",
    "            region_numbering = 1\n",
    "        elif position > region.lower and position <= region.upper - 1: # inside region: increment region numbering normally\n",
    "            # find paired base, or skip if base is the opposite strand\n",
    "            if ss[position] == \"(\":\n",
    "                paired_base = regions[-1].upper - (position - regions[0].lower) - 1\n",
    "                positions.append(Position(position='{}:{}'.format(position + 1, paired_base + 1), region=region.name, region_number=region_numbering + 1, paired=True))\n",
    "            elif ss[position] == \"<\":\n",
    "                paired_base = regions[region_index + 2].upper - region_numbering - 1\n",
    "                positions.append(Position(position='{}:{}'.format(position + 1, paired_base + 1), region=region.name, region_number=region_numbering + 1, paired=True))\n",
    "            elif ss[position] in [')', '>']:\n",
    "                pass\n",
    "            else:\n",
    "                positions.append(Position(position=str(position + 1), region=region.name, region_number=region_numbering+1, paired=False))\n",
    "            region_numbering += 1\n",
    "        if position == region.upper - 1: # end of region, reset region index and increment region number\n",
    "            region_index += 1\n",
    "            region_numbering = 0\n",
    "        \n",
    "    return positions\n",
    "\n",
    "def count_positions(input_file, positions):\n",
    "    # We've now annotated all of the positions. Time to count bases at each position.\n",
    "    # Loop through all sequences in alignment\n",
    "    alignment_fhandle = open(input_file) # refresh handle\n",
    "    for line in alignment_fhandle:\n",
    "        if line[0] in [\"#\", '\\n', '/']: continue\n",
    "        if len(line.split()) == 1: print(line)\n",
    "        seqname, seq = line.strip().split()\n",
    "        for seq_index, base in enumerate(seq): positions[seq_index].counts[base] += 1\n",
    "    for index, position in enumerate(positions):\n",
    "        positions[index].num_obs = sum(positions[index].counts.values())\n",
    "    return positions\n",
    "\n",
    "class Position:\n",
    "    def __init__(self, position, region, region_number, paired=False, counts=Counter(), num_obs=0):\n",
    "        self.position = position\n",
    "        self.region = region\n",
    "        self.region_number = region_number\n",
    "        self.paired = paired\n",
    "        self.counts = counts\n",
    "        self.num_obs = num_obs        \n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Position {} ({} #{})\".format(self.position, self.region, self.region_number)\n",
    "\n",
    "class Region:\n",
    "    def __init__(self, lower, upper, name):\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.name = name\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Region {} ({} ~ {})\".format(self.name, self.lower, self.upper)\n",
    "\n",
    "positions = parse_alignment('euk-Leu.sto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-168-a647d6be028e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ss' is not defined"
     ]
    }
   ],
   "source": [
    "print(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
