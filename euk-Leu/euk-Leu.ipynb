{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Previously, we looked at fungal leucine tRNAs in GtRNAdb. Next, we're going to look at all eukaryotic leucine tRNAs in GtRNAdb. This will involve two extra steps. I'll need to build a phylogenetic tree, which will be used for autodetection of identity elements. This will replace the hardcoded yeast IDEs. \n",
    "\n",
    "We've learned that in fungi, the lower bound for _percentage of tRNAs missing an IDE_ is 20% in a single species, while every single species contained at least one tRNA with the proper IDEs. So for autodetection of IDEs, what can we set as a cutoff? What if all but one species has the IDEs? This could mean that the one species has a mutated synthetase. We need to set a boundary for the amount of evidence that will convince us that a conserved position is an identity element. I'd say that if 80% of species within a clade have the IDE in at least one tRNA, then it's convincing. \n",
    "\n",
    "## Workflow\n",
    "One potential workflow is as follows:\n",
    "1. Generate multi-tiered phylogenetic tree\n",
    "2. Align and filter tRNAs from each clade\n",
    "3. For each clade, find and score potential IDEs.\n",
    "    - This includes base pairs and single bases.\n",
    "    - Scoring will need to take into account a) number of species with at least one tRNA with the IDE, and b) percent of tRNAs with the IDE within each species. (a) is a scalar, while (b) is a vector. So we'll take the product of (a) and the mean of (b), for a score between 0 and 1. Let $s$ be the number of subclades in the clade, while $s_i$ is the subset of subclades containing at least one tRNA with an IDE $i$. $s$ can refer to species (e.g. _S. cerevisiae_ within fungi) or clades (e.g. fungi within eukaryotes). Let $t_s$ be the number of tRNAs within a subclade $s$, and $t_i$ be the number of tRNAs containing an IDE $i$. Then: \n",
    "$$\\text{Score} = \\frac{s_i}{s}\\frac{\\sum^s{t_{s,i}}}{s}$$\n",
    "    - As a heuristic, we will not score any positions with $s_i < 0.8$.\n",
    "4. Imagine a phylogenetic tree with root R branching into clades A, B, and C. If steps #2-#4 are performed for each of A, B, and C, we will now want to perform a R-wide analysis of the IDEs identified within subclades A, B, and C. Since this IDE analysis is entirely computational, some phylogenetic context is necessary. Then, we will want to perform a t-test for the scores of each IDE, between R and A (or B or C). The null hypothesis is that they are the same, e.g. conserved. \n",
    "    - Alternatively, we can assume that positions without evolutionary pressure have scores that follow a normal distribution, with a mean of $0.25 \\cdot 0.25 = 0.0625$. But tRNAs are subject to a variety of compounding pressures, and have different evolutionary timelines, so actually, this is a silly assumption.\n",
    "    - Either way, we will need to apply multiple testing corrections.\n",
    "    \n",
    "Unfortunately, this would fail in the case where the same position is mutated among different clades - for example, maybe fungi have A35 while mammals have G35. This requires a positional analysis. Instead of counting the number of tRNAs with an IDE, we can look at the R-wide information content. In theory, low information content means conservation. \n",
    "\n",
    "Given a method for finding positional IDE information, we should start with a list of positional IDEs, then try to resolve nucleotides. This also eliminates the need for subclade IDE autodetection, and instead we can just take the base or nucleotide at the proper position. So, we'll need to develop a cutoff for entropy. This would be used to determine the position of the base. Then we'd have to figure out a clade-wide nucleotide, which also needs a cutoff. I'm not too worried about this second cutoff, since we can just say something like 80%, and reanalyze subclades - the important thing is the entropy of the position. \n",
    "\n",
    "## Revised workflow\n",
    "1. Generate multi-tiered phylogenetic tree\n",
    "2. Align and filter tRNAs from each clade\n",
    "3. **Find positions under entropy cutoff**\n",
    "4. Resolve nucleotides corresponding to positions, if possible.\n",
    "5. Resolve nucleotides for subclades.\n",
    "\n",
    "In this notebook, I'll be performing this analysis for eukaryotic leucine tRNAs in order to find an appropriate entropy cutoff. Leucine is a good system since it is well studied, and has shared as well as differing IDEs between yeast and human. \n",
    "\n",
    "Later, we will want to look at identity element \"suites\" - what combinations of identity elements can be persistently found throughout a clade? This would be able to match the brain-specific arginine across species.\n",
    "\n",
    "### Yeast/human leucine IDEs\n",
    "Shard     |Yeast    |Human           |\n",
    ":--------|---------|-----------------:\n",
    "A73      |G35, G37 |C3:G70, A4:U69, G5:C68, C20a\n",
    "\n",
    "We have a couple of options for determining entropy.\n",
    "\n",
    "First, we can parse the alignment itself. For example, there are 925 As, 4 Us, and 21 Gs at position 73. There are also 2 Ns and 2 '-'s, which we don't count. Average entropy here is\n",
    "\n",
    "$$-\\sum^np_i\\log_2{p_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19225738255857028"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log2\n",
    "-925/950*log2(925/950) - 4/950*log2(4/950) - 21/950*log2(21/950)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at position 69, this is the entropy you'd see from a typical position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "935"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 184 As, 36 Gs, 426 Us, 289 Cs\n",
    "184+36+426+289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6827342976356228"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(n, total): return -n/total*log2(n/total)\n",
    "entropy(184, 935) + entropy(36, 935) + entropy(426, 935) + entropy(289, 935)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought about building a covariance model and parse the file to get emission log-odds bit scores for each possible nucleotide or base pair. This is different from what I calculated above: odds and probability are different. \n",
    "\n",
    "It's not clear how to consolidate log-odds into single positional scores. Range is loosely correlated with conservation for strong IDEs, but what if we had a subclade mutate the base at that position? Then for the position, we'd see a smaller range of bit scores, and it would be indistinguishable from variation. Overall, not being able to resolve multiple log odds scores into a scalar is probably because the range of possible odds is [0, $\\infty$]. Unlike probabilities, which sum to 1, odds are unbounded. What we could do is recover the probabilities by taking the root inverse log. Then we can aggregate them using the above process.\n",
    "\n",
    "But that would take too long, and we're trying to get a move on here. We'll stick with the former, finding positions with minimum entropy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding an entropy cutoff\n",
    "\n",
    "We'll come back to building a phylogenetic tree later. First, we'll get the entropy at each position and see if there's an easy cutoff. We use the R2 alignment used to build the leucine-specific CM, and also just the fungal tRNAs. Again, we use `--matchonly` to get the proper numbering, and ignore potential insertions/deletions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp ../gtrnadb-fungi/fungi-Leu-tRNAs.sto .\n",
    "cp ../../tRNAscan/models/1.6/fasta/euk-Leu-r2-031616.fa euk-Leu.fa\n",
    "cmalign -g --notrunc --matchonly -o euk-Leu.sto /projects/lowelab/users/blin/tRNAscan/models/current/TRNAinf-euk-Leu.cm euk-Leu.fa > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to dynamically determine what the secondary structure looks like. I use a combination of Sprinzl numbering and region numbering to track positions, since there are some weird tRNAs out there (variable loop, long D arm/D loop, G0, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7), (9, 13), (13, 22), (22, 26), (27, 32), (32, 39), (39, 44), (45, 49), (49, 53), (53, 57), (59, 64), (64, 71), (71, 76), (76, 83)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def parse_alignment(input_file, output_file):\n",
    "    entropy_fhandle = open(output_file, 'w')\n",
    "    alignment_fhandle = open(input_file)\n",
    "    positions = [] # list containing each position in the tRNA\n",
    "\n",
    "    # first, get secondary structure\n",
    "    for line in alignment_fhandle:\n",
    "        if line[0:12] == '#=GC SS_cons':\n",
    "            ss = line.strip().split()[-1]\n",
    "    loop_indices = [r.span() for r in re.finditer('\\(+|<+|_+|>+|\\)+', ss)]\n",
    "    if len(loop_indices) == 14: regions = ['acceptor', 'dstem', 'dloop', 'dstem', 'acstem', 'acloop', 'acstem', 'vstem', 'vloop', 'vstem', 'tpcstem', 'tpcloop', 'tpcstem', 'acstem']\n",
    "    elif len(loop_indices) == 11: regions = ['acceptor', 'dstem', 'dloop', 'dstem', 'acstem', 'acloop', 'acstem', 'tpcstem', 'tpcloop', 'tpcstem', 'acstem']\n",
    "    print(loop_indices)\n",
    "    regions = [Region(indices[0], indices[1], name) for indices, name in zip(loop_indices, regions[:])]\n",
    "    positions = []\n",
    "    region_index = 0 # index to be used to iterate through regions list\n",
    "    region_numbering = 0 # base numbering within a region\n",
    "    for position in range(len(ss)):\n",
    "        if region_index == len(regions):\n",
    "            positions.append(Position(position + 1, 'single', region_numbering + 1))\n",
    "            region_numbering += 1\n",
    "            continue\n",
    "        region = regions[region_index]\n",
    "        if position < region.lower:\n",
    "            positions.append(Position(position + 1, 'single', region_numbering + 1))\n",
    "            region_numbering += 1\n",
    "        elif position == region.lower: # beginning of region: begin region numbering at 1\n",
    "            positions.append(Position(position + 1, regions[region_index].name, 1))\n",
    "            region_numbering = 1\n",
    "        elif position > region.lower and position < region.upper: # inside region: increment region numbering\n",
    "            positions.append(Position(position + 1, regions[region_index].name, region_numbering + 1))\n",
    "            region_numbering += 1\n",
    "        elif position == region.upper: # end of region, reset region index and increment region number\n",
    "            # if this is the beginning of a new region, add a new region position\n",
    "            if region_index + 1 != len(regions) and position == regions[region_index + 1].lower:\n",
    "                positions.append(Position(position + 1, regions[region_index + 1].name, 1))\n",
    "            else: \n",
    "            # otherwise, add a single position\n",
    "                positions.append(Position(position + 1, 'single', 1))\n",
    "            region_index += 1\n",
    "            region_numbering = 1\n",
    "    \n",
    "    # We've now annotated all of the positions. Time to count bases at each position.\n",
    "    # Loop through all sequences in alignment\n",
    "    alignment_fhandle = open(input_file) # refresh handle\n",
    "    for line in alignment_fhandle:\n",
    "        if line[0] == \"#\": continue\n",
    "        _, seqname, seq = line.strip().split()\n",
    "        for base in seq:\n",
    "    \n",
    "    for position in positions:\n",
    "        position.status = \"unknown\"\n",
    "\n",
    "class Position:\n",
    "  def __init__(self, sprinzl_number, region, region_number, A=0, C=0, G=0, T=0, num_obs=0):\n",
    "    self.sprinzl_number = sprinzl_number\n",
    "    self.region = region\n",
    "    self.region_number = region_number\n",
    "    self.A = A\n",
    "    self.G = G\n",
    "    self.T = T\n",
    "    self.C = C\n",
    "    self.num_obs = 0\n",
    "    \n",
    "  def __str__(self):\n",
    "    return \"-->Base #{} ({} #{})\".format(self.sprinzl_number, self.region, self.region_number)\n",
    "\n",
    "class Region:\n",
    "    def __init__(self, lower, upper, name):\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.name = name\n",
    "\n",
    "parse_alignment('euk-Leu.sto', 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
